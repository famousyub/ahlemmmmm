{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0092a796",
   "metadata": {},
   "source": [
    "# Homomorphic Encryption and Federated Learning based Privacy-Preserving: Breast cancer detection Use-Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ed5aad",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Medical data is often highly sensitive in terms of data privacy and security concerns. Federated learning, one type of machine learning techniques, has been started to use for the improvement of the privacy and security of medical data. In the federated learning, the training data is distributed across multiple machines, and the\n",
    "learning process is performed in a collaborative manner. There are several privacy attacks on machine learning (ML) models to get the sensitive information by attackers. Therefore, the ML model itself should be protected from the adversarial attack, especially for applications using medical data. One of the solutions for this problem is homomorphic encryption-based model protection from the adversary collaborator. This project proposes a privacy-preserving federated learning algorithm for medical data using homomorphic encryption. The proposed algorithm uses a secure multi-party computation protocol to protect the machine learning model from the adversaries. In this study, the proposed algorithm using a real-world medical dataset is evaluated in terms of the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c7f12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Last updated: 2023-06-17T21:36:12.093524+07:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.9\n",
      "IPython version      : 8.10.0\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 5.19.0-45-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5590bb95",
   "metadata": {},
   "source": [
    "Before step into federated learning, lets talk about Logistic Regression - a local training method we use in our federated learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132c4ab1",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2be267bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  fractal_dimension_worst  radius_mean  texture_mean  \\\n",
       "0    842302                  0.11890        17.99         10.38   \n",
       "1    842517                  0.08902        20.57         17.77   \n",
       "2  84300903                  0.08758        19.69         21.25   \n",
       "3  84348301                  0.17300        11.42         20.38   \n",
       "4  84358402                  0.07678        20.29         14.34   \n",
       "\n",
       "   perimeter_mean  area_mean  smoothness_mean  compactness_mean  \\\n",
       "0          122.80     1001.0          0.11840           0.27760   \n",
       "1          132.90     1326.0          0.08474           0.07864   \n",
       "2          130.00     1203.0          0.10960           0.15990   \n",
       "3           77.58      386.1          0.14250           0.28390   \n",
       "4          135.10     1297.0          0.10030           0.13280   \n",
       "\n",
       "   concavity_mean  concave points_mean  ...  radius_worst  texture_worst  \\\n",
       "0          0.3001              0.14710  ...         25.38          17.33   \n",
       "1          0.0869              0.07017  ...         24.99          23.41   \n",
       "2          0.1974              0.12790  ...         23.57          25.53   \n",
       "3          0.2414              0.10520  ...         14.91          26.50   \n",
       "4          0.1980              0.10430  ...         22.54          16.67   \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0           184.60      2019.0            0.1622             0.6656   \n",
       "1           158.80      1956.0            0.1238             0.1866   \n",
       "2           152.50      1709.0            0.1444             0.4245   \n",
       "3            98.87       567.7            0.2098             0.8663   \n",
       "4           152.20      1575.0            0.1374             0.2050   \n",
       "\n",
       "   concavity_worst  concave points_worst  symmetry_worst  diagnosis  \n",
       "0           0.7119                0.2654          0.4601          M  \n",
       "1           0.2416                0.1860          0.2750          M  \n",
       "2           0.4504                0.2430          0.3613          M  \n",
       "3           0.6869                0.2575          0.6638          M  \n",
       "4           0.4000                0.1625          0.2364          M  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# we use another datasets to demo our Logistic Regression\n",
    "df = pd.read_csv(\"data/breast-cancer.csv\")\n",
    "\n",
    "# define function to swap columns\n",
    "def swap_columns(df, col1, col2):\n",
    "    col_list = list(df.columns)\n",
    "    x, y = col_list.index(col1), col_list.index(col2)\n",
    "    col_list[y], col_list[x] = col_list[x], col_list[y]\n",
    "    df = df[col_list]\n",
    "    return df\n",
    "\n",
    "# swap \"diagnosis\" and \"fractal_dimension_worst\" columns\n",
    "df = swap_columns(df, 'diagnosis', 'fractal_dimension_worst')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db30fcc",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17a0ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7366ae",
   "metadata": {},
   "source": [
    "Replace \"M\" with 1 and \"B\" with 0 at \"diagnosis\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9548210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \"M\" with 1 and \"B\" with 0\n",
    "df[\"diagnosis\"] = (df[\"diagnosis\"] == \"M\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8836ba",
   "metadata": {},
   "source": [
    "We define some functions in order to randomly split this dataset to:\n",
    "- Training dataset (80%)\n",
    "- Testing dataset  (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "188c50f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset(name, data):\n",
    "    print('Dataset {}. Shape: {}'.format(name, data.shape))\n",
    "    print(data[:5])\n",
    "    \n",
    "def scale_dataset(df, overSample=False):\n",
    "    # split to fetures and diagnostic result\n",
    "    X = df[df.columns[:-1]].values\n",
    "    Y = df[df.columns[-1]].values\n",
    "    \n",
    "    # standardize the input features \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # balance the class distribution\n",
    "    if overSample:\n",
    "        ros = RandomOverSampler()\n",
    "        X, Y = ros.fit_resample(X, Y)\n",
    "\n",
    "    data = np.hstack((X, np.reshape(Y, (-1, 1))))\n",
    "    \n",
    "    # convert to tensor context\n",
    "    X_train_tensor = Variable(torch.tensor(X, dtype = torch.float32))\n",
    "    Y_train_tensor = Variable(torch.tensor(Y, dtype = torch.float32))\n",
    "    data_tensor    = Variable(torch.tensor(data, dtype = torch.float32))\n",
    "    \n",
    "    return data_tensor, X_train_tensor, Y_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "429b827c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2264, -0.9424, -0.7172,  ..., -1.0148,  0.5912,  0.0000],\n",
       "        [ 0.4751,  1.1349,  0.4788,  ...,  1.0389,  1.5109,  1.0000],\n",
       "        [-0.2267, -0.7194, -0.1907,  ..., -0.0401,  0.1716,  1.0000],\n",
       "        ...,\n",
       "        [ 0.4975,  0.6004,  0.6733,  ...,  1.3867,  0.2723,  1.0000],\n",
       "        [-0.2331, -0.4657,  1.5575,  ...,  1.0621, -0.5299,  1.0000],\n",
       "        [-0.2265,  0.1794,  2.6275,  ...,  2.4658,  0.5140,  1.0000]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataframe to train and test df\n",
    "df_train, df_test = np.split(df.sample(frac=1), [int(0.8 * len(df))])\n",
    "\n",
    "# scaling and convert to tensor context\n",
    "train, X_train, Y_train = scale_dataset(df_train, True)\n",
    "test , X_test , Y_test  = scale_dataset(df_test , False)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514f8b55",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9ddc6",
   "metadata": {},
   "source": [
    "We define our machine learning model, which is a logistic regression model. Why? Because this medical dataset is linearly separable, which simplifies things a lot.\n",
    "\n",
    "We can create the logistic regression model with the following code (we will using [pyTorch](https://en.wikipedia.org/wiki/PyTorch) in our project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a32c86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "669c0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        # init super class of LogisticRegression\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        \n",
    "        # create \"linear neural network\"\n",
    "        input_dim  = num_features\n",
    "        output_dim = 1\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "        # initialize Weights and Bias\n",
    "        self.linear.weight.detach().zero_()\n",
    "        self.linear.bias.detach().zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c7eb24",
   "metadata": {},
   "source": [
    "In our “forward” pass of the PyTorch neural network (really just a perceptron), Logistic regression can also be visualized as a network of features feeding into a single logistic function, the visual representation and corresponding equations are shown below:\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='images/logistic_model_overview.png'>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d690b8d",
   "metadata": {},
   "source": [
    "### Sigmoid function\n",
    "\n",
    "The sigmoid function is extremely useful for two main reasons:\n",
    "\n",
    "* It transforms our linear regression output to a probability from 0 to 1. We can then take any probability greater than 0.5 as being 1 and below as being 0.\n",
    "\n",
    "* Unlike a stepwise function (which would transform the data into the binary case as well), the sigmoid is differentiable, which is necessary for optimizing the parameters using gradient descent (we will show later).\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='images/sigmoid.png'>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f8f15",
   "metadata": {},
   "source": [
    "### Training process\n",
    "\n",
    "Firstly, we should assign some hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ec346ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 31 # numbers of features \n",
    "epochs = 10000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78085473",
   "metadata": {},
   "source": [
    "Parameter Definitions:\n",
    "\n",
    "* **Epoch**: Indicates the number of passes through the entire training dataset the network has completed.\n",
    "* **learning_rate**: A tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1e760bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "def decide(y):\n",
    "    return 1. if y >= 0.5 else 0.\n",
    "\n",
    "decide_vectorized = np.vectorize(decide)\n",
    "to_percent = lambda x: '{:.2f}%'.format(x)\n",
    "\n",
    "def compute_accuracy(model, input, output):\n",
    "    prediction = model(input).data.numpy()[:, 0]\n",
    "    n_samples = prediction.shape[0] + 0.\n",
    "    prediction = decide_vectorized(prediction)\n",
    "    equal = prediction == output.data.numpy()\n",
    "    return 100. * equal.sum() / n_samples\n",
    "\n",
    "def Training(X_train, Y_train, X_test, Y_test, debug=True):\n",
    "    model = LogisticRegression(input_dim)\n",
    "    n_samples, _ = X_train.shape\n",
    "    \n",
    "    # record losses and accuracies during training\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    # define criterion function and set up optimizer\n",
    "    criterion = torch.nn.BCELoss(reduction='mean')\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "    \n",
    "    # main process\n",
    "    for epoch in tqdm(range(epochs)):  \n",
    "        optimizer.zero_grad()\n",
    "        #### Compute outputs ####\n",
    "        prediction = model(X_train)\n",
    "        \n",
    "        #### Compute gradients ####\n",
    "        loss = criterion(prediction.squeeze(), Y_train)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #### Update weights #### \n",
    "        optimizer.step()\n",
    "            \n",
    "        #### Logging ####\n",
    "        if debug and (epoch + 1)%50 == 0:\n",
    "            # compute accuracy and loss\n",
    "            train_acc = compute_accuracy(model, X_train, Y_train)\n",
    "            train_loss = loss.item()\n",
    "            losses.append(train_loss)\n",
    "            accuracies.append(train_acc)\n",
    "            \n",
    "            print('[LOG] Epoch: %05d' % (epoch + 1), end=\"\")\n",
    "            print('    | Train ACC: %s' % to_percent(train_acc), end=\"\")\n",
    "            print('    | Loss: %.3f' % train_loss)\n",
    "\n",
    "    recorded = [accuracies, losses]\n",
    "    return model, recorded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e289c595",
   "metadata": {},
   "source": [
    "In this above code, we introduce two important functions: the Loss Function and the Optimizer\n",
    "\n",
    "**Binary Cross Entropy Loss Function**\n",
    "\n",
    "```python\n",
    "criterion = torch.nn.BCELoss(reduction='mean')\n",
    "```\n",
    "<p align='center'>\n",
    "    <img src='images/loss_function.png'>\n",
    "</p>\n",
    "\n",
    "* $m$: Number of training examples\n",
    "* $y$: The true $y$ value\n",
    "* $\\hat{y}$: Predicted $y$ value\n",
    "\n",
    "**Stochastic Gradient Descent Optimizer**\n",
    "\n",
    "```python\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "```\n",
    "\n",
    "We update the parameters to minimize the loss function with the following equations:\n",
    "\n",
    "* Update model **Weights**:\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='images/update_w.webp'>\n",
    "</p>\n",
    "\n",
    "* Update model **Bias**:\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='images/update_b.webp'>\n",
    "</p>\n",
    "\n",
    "where $\\alpha$ is the **learning_rate**\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='images/gradient_descent.png' title='Gradient Descent'>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7197c",
   "metadata": {},
   "source": [
    "Demo our training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31ad3d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Epoch: 00050    | Train ACC: 94.76%    | Loss: 0.329\n",
      "[LOG] Epoch: 00100    | Train ACC: 95.63%    | Loss: 0.252\n",
      "[LOG] Epoch: 00150    | Train ACC: 95.80%    | Loss: 0.215\n",
      "[LOG] Epoch: 00200    | Train ACC: 96.33%    | Loss: 0.192\n",
      "[LOG] Epoch: 00250    | Train ACC: 96.68%    | Loss: 0.177\n",
      "[LOG] Epoch: 00300    | Train ACC: 96.50%    | Loss: 0.165\n",
      "[LOG] Epoch: 00350    | Train ACC: 96.50%    | Loss: 0.156\n",
      "[LOG] Epoch: 00400    | Train ACC: 96.85%    | Loss: 0.148\n",
      "[LOG] Epoch: 00450    | Train ACC: 96.50%    | Loss: 0.142\n",
      "[LOG] Epoch: 00500    | Train ACC: 96.68%    | Loss: 0.137\n",
      "[LOG] Epoch: 00550    | Train ACC: 96.68%    | Loss: 0.133\n",
      "[LOG] Epoch: 00600    | Train ACC: 96.68%    | Loss: 0.129\n",
      "[LOG] Epoch: 00650    | Train ACC: 96.68%    | Loss: 0.125\n",
      "[LOG] Epoch: 00700    | Train ACC: 96.68%    | Loss: 0.122\n",
      "[LOG] Epoch: 00750    | Train ACC: 96.85%    | Loss: 0.119\n",
      "[LOG] Epoch: 00800    | Train ACC: 97.03%    | Loss: 0.117\n",
      "[LOG] Epoch: 00850    | Train ACC: 97.03%    | Loss: 0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Epoch: 00900    | Train ACC: 97.03%    | Loss: 0.113\n",
      "[LOG] Epoch: 00950    | Train ACC: 97.03%    | Loss: 0.111\n",
      "[LOG] Epoch: 01000    | Train ACC: 97.03%    | Loss: 0.109\n",
      "[LOG] Epoch: 01050    | Train ACC: 97.03%    | Loss: 0.107\n",
      "[LOG] Epoch: 01100    | Train ACC: 97.03%    | Loss: 0.106\n",
      "[LOG] Epoch: 01150    | Train ACC: 97.03%    | Loss: 0.104\n",
      "[LOG] Epoch: 01200    | Train ACC: 97.38%    | Loss: 0.103\n",
      "[LOG] Epoch: 01250    | Train ACC: 97.38%    | Loss: 0.102\n",
      "[LOG] Epoch: 01300    | Train ACC: 97.38%    | Loss: 0.101\n",
      "[LOG] Epoch: 01350    | Train ACC: 97.38%    | Loss: 0.099\n",
      "[LOG] Epoch: 01400    | Train ACC: 97.55%    | Loss: 0.098\n",
      "[LOG] Epoch: 01450    | Train ACC: 97.55%    | Loss: 0.097\n",
      "[LOG] Epoch: 01500    | Train ACC: 97.55%    | Loss: 0.096\n",
      "[LOG] Epoch: 01550    | Train ACC: 97.55%    | Loss: 0.096\n",
      "[LOG] Epoch: 01600    | Train ACC: 97.55%    | Loss: 0.095\n",
      "[LOG] Epoch: 01650    | Train ACC: 97.55%    | Loss: 0.094\n",
      "[LOG] Epoch: 01700    | Train ACC: 97.55%    | Loss: 0.093\n",
      "[LOG] Epoch: 01750    | Train ACC: 97.73%    | Loss: 0.092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Epoch: 01800    | Train ACC: 97.73%    | Loss: 0.092\n",
      "[LOG] Epoch: 01850    | Train ACC: 97.73%    | Loss: 0.091\n",
      "[LOG] Epoch: 01900    | Train ACC: 97.73%    | Loss: 0.090\n",
      "[LOG] Epoch: 01950    | Train ACC: 97.73%    | Loss: 0.090\n",
      "[LOG] Epoch: 02000    | Train ACC: 97.73%    | Loss: 0.089\n",
      "[LOG] Epoch: 02050    | Train ACC: 97.73%    | Loss: 0.089\n",
      "[LOG] Epoch: 02100    | Train ACC: 97.73%    | Loss: 0.088\n",
      "[LOG] Epoch: 02150    | Train ACC: 97.73%    | Loss: 0.087\n",
      "[LOG] Epoch: 02200    | Train ACC: 97.73%    | Loss: 0.087\n",
      "[LOG] Epoch: 02250    | Train ACC: 97.73%    | Loss: 0.086\n",
      "[LOG] Epoch: 02300    | Train ACC: 97.73%    | Loss: 0.086\n",
      "[LOG] Epoch: 02350    | Train ACC: 97.73%    | Loss: 0.085\n",
      "[LOG] Epoch: 02400    | Train ACC: 97.73%    | Loss: 0.085\n",
      "[LOG] Epoch: 02450    | Train ACC: 97.73%    | Loss: 0.085\n",
      "[LOG] Epoch: 02500    | Train ACC: 97.73%    | Loss: 0.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Epoch: 02550    | Train ACC: 97.73%    | Loss: 0.084\n",
      "[LOG] Epoch: 02600    | Train ACC: 97.73%    | Loss: 0.083\n",
      "[LOG] Epoch: 02650    | Train ACC: 97.73%    | Loss: 0.083\n",
      "[LOG] Epoch: 02700    | Train ACC: 97.73%    | Loss: 0.083\n",
      "[LOG] Epoch: 02750    | Train ACC: 97.73%    | Loss: 0.082\n",
      "[LOG] Epoch: 02800    | Train ACC: 97.73%    | Loss: 0.082\n",
      "[LOG] Epoch: 02850    | Train ACC: 97.73%    | Loss: 0.082\n",
      "[LOG] Epoch: 02900    | Train ACC: 97.73%    | Loss: 0.081\n",
      "[LOG] Epoch: 02950    | Train ACC: 97.73%    | Loss: 0.081\n",
      "[LOG] Epoch: 03000    | Train ACC: 97.73%    | Loss: 0.081\n",
      "[LOG] Epoch: 03050    | Train ACC: 97.73%    | Loss: 0.080\n",
      "[LOG] Epoch: 03100    | Train ACC: 97.73%    | Loss: 0.080\n",
      "[LOG] Epoch: 03150    | Train ACC: 97.73%    | Loss: 0.080\n",
      "[LOG] Epoch: 03200    | Train ACC: 97.73%    | Loss: 0.079\n",
      "[LOG] Epoch: 03250    | Train ACC: 97.73%    | Loss: 0.079\n",
      "[LOG] Epoch: 03300    | Train ACC: 97.73%    | Loss: 0.079\n",
      "[LOG] Epoch: 03350    | Train ACC: 97.73%    | Loss: 0.079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Epoch: 03400    | Train ACC: 97.73%    | Loss: 0.078\n",
      "[LOG] Epoch: 03450    | Train ACC: 97.73%    | Loss: 0.078\n",
      "[LOG] Epoch: 03500    | Train ACC: 97.73%    | Loss: 0.078\n",
      "[LOG] Epoch: 03550    | Train ACC: 97.73%    | Loss: 0.078\n",
      "[LOG] Epoch: 03600    | Train ACC: 97.73%    | Loss: 0.077\n",
      "[LOG] Epoch: 03650    | Train ACC: 97.73%    | Loss: 0.077\n",
      "[LOG] Epoch: 03700    | Train ACC: 97.73%    | Loss: 0.077\n",
      "[LOG] Epoch: 03750    | Train ACC: 97.73%    | Loss: 0.077\n",
      "[LOG] Epoch: 03800    | Train ACC: 97.73%    | Loss: 0.076\n",
      "[LOG] Epoch: 03850    | Train ACC: 97.73%    | Loss: 0.076\n",
      "[LOG] Epoch: 03900    | Train ACC: 97.73%    | Loss: 0.076\n",
      "[LOG] Epoch: 03950    | Train ACC: 97.73%    | Loss: 0.076\n",
      "[LOG] Epoch: 04000    | Train ACC: 97.73%    | Loss: 0.076\n",
      "[LOG] Epoch: 04050    | Train ACC: 97.73%    | Loss: 0.075\n",
      "[LOG] Epoch: 04100    | Train ACC: 97.73%    | Loss: 0.075\n",
      "[LOG] Epoch: 04150    | Train ACC: 97.73%    | Loss: 0.075\n",
      "[LOG] Epoch: 04200    | Train ACC: 97.73%    | Loss: 0.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Epoch: 04250    | Train ACC: 97.73%    | Loss: 0.075\n",
      "[LOG] Epoch: 04300    | Train ACC: 97.73%    | Loss: 0.074\n",
      "[LOG] Epoch: 04350    | Train ACC: 97.73%    | Loss: 0.074\n",
      "[LOG] Epoch: 04400    | Train ACC: 97.73%    | Loss: 0.074\n",
      "[LOG] Epoch: 04450    | Train ACC: 97.73%    | Loss: 0.074\n",
      "[LOG] Epoch: 04500    | Train ACC: 97.73%    | Loss: 0.074\n",
      "[LOG] Epoch: 04550    | Train ACC: 97.73%    | Loss: 0.073\n",
      "[LOG] Epoch: 04600    | Train ACC: 97.73%    | Loss: 0.073\n",
      "[LOG] Epoch: 04650    | Train ACC: 97.73%    | Loss: 0.073\n",
      "[LOG] Epoch: 04700    | Train ACC: 97.73%    | Loss: 0.073\n",
      "[LOG] Epoch: 04750    | Train ACC: 97.73%    | Loss: 0.073\n",
      "[LOG] Epoch: 04800    | Train ACC: 97.73%    | Loss: 0.073\n",
      "[LOG] Epoch: 04850    | Train ACC: 97.73%    | Loss: 0.073\n",
      "[LOG] Epoch: 04900    | Train ACC: 97.73%    | Loss: 0.072\n",
      "[LOG] Epoch: 04950    | Train ACC: 97.73%    | Loss: 0.072\n",
      "[LOG] Epoch: 05000    | Train ACC: 97.73%    | Loss: 0.072\n",
      "[LOG] Epoch: 05050    | Train ACC: 97.73%    | Loss: 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5050/10000 [00:01<00:01, 3961.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Epoch: 05100    | Train ACC: 97.73%    | Loss: 0.072\n",
      "[LOG] Epoch: 05150    | Train ACC: 97.73%    | Loss: 0.072\n",
      "[LOG] Epoch: 05200    | Train ACC: 97.73%    | Loss: 0.072\n",
      "[LOG] Epoch: 05250    | Train ACC: 97.73%    | Loss: 0.071\n",
      "[LOG] Epoch: 05300    | Train ACC: 97.73%    | Loss: 0.071\n",
      "[LOG] Epoch: 05350    | Train ACC: 97.73%    | Loss: 0.071\n",
      "[LOG] Epoch: 05400    | Train ACC: 97.73%    | Loss: 0.071\n",
      "[LOG] Epoch: 05450    | Train ACC: 97.73%    | Loss: 0.071\n",
      "[LOG] Epoch: 05500    | Train ACC: 97.73%    | Loss: 0.071\n",
      "[LOG] Epoch: 05550    | Train ACC: 97.73%    | Loss: 0.071\n",
      "[LOG] Epoch: 05600    | Train ACC: 97.73%    | Loss: 0.070\n",
      "[LOG] Epoch: 05650    | Train ACC: 97.73%    | Loss: 0.070\n",
      "[LOG] Epoch: 05700    | Train ACC: 97.73%    | Loss: 0.070\n",
      "[LOG] Epoch: 05750    | Train ACC: 97.73%    | Loss: 0.070\n",
      "[LOG] Epoch: 05800    | Train ACC: 97.73%    | Loss: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5841/10000 [00:01<00:01, 3933.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Epoch: 05850    | Train ACC: 97.73%    | Loss: 0.070\n",
      "[LOG] Epoch: 05900    | Train ACC: 97.73%    | Loss: 0.070\n",
      "[LOG] Epoch: 05950    | Train ACC: 97.73%    | Loss: 0.070\n",
      "[LOG] Epoch: 06000    | Train ACC: 97.73%    | Loss: 0.070\n",
      "[LOG] Epoch: 06050    | Train ACC: 97.73%    | Loss: 0.069\n",
      "[LOG] Epoch: 06100    | Train ACC: 97.73%    | Loss: 0.069\n",
      "[LOG] Epoch: 06150    | Train ACC: 97.73%    | Loss: 0.069\n",
      "[LOG] Epoch: 06200    | Train ACC: 97.73%    | Loss: 0.069\n",
      "[LOG] Epoch: 06250    | Train ACC: 97.73%    | Loss: 0.069\n",
      "[LOG] Epoch: 06300    | Train ACC: 97.73%    | Loss: 0.069\n",
      "[LOG] Epoch: 06350    | Train ACC: 97.73%    | Loss: 0.069\n",
      "[LOG] Epoch: 06400    | Train ACC: 97.73%    | Loss: 0.069\n",
      "[LOG] Epoch: 06450    | Train ACC: 97.73%    | Loss: 0.069\n",
      "[LOG] Epoch: 06500    | Train ACC: 97.73%    | Loss: 0.068\n",
      "[LOG] Epoch: 06550    | Train ACC: 97.73%    | Loss: 0.068\n",
      "[LOG] Epoch: 06600    | Train ACC: 97.73%    | Loss: 0.068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 6644/10000 [00:01<00:00, 3957.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Epoch: 06650    | Train ACC: 97.73%    | Loss: 0.068\n",
      "[LOG] Epoch: 06700    | Train ACC: 97.73%    | Loss: 0.068\n",
      "[LOG] Epoch: 06750    | Train ACC: 97.73%    | Loss: 0.068\n",
      "[LOG] Epoch: 06800    | Train ACC: 97.73%    | Loss: 0.068\n",
      "[LOG] Epoch: 06850    | Train ACC: 97.73%    | Loss: 0.068\n",
      "[LOG] Epoch: 06900    | Train ACC: 97.73%    | Loss: 0.068\n",
      "[LOG] Epoch: 06950    | Train ACC: 97.73%    | Loss: 0.068\n",
      "[LOG] Epoch: 07000    | Train ACC: 97.73%    | Loss: 0.068\n",
      "[LOG] Epoch: 07050    | Train ACC: 97.73%    | Loss: 0.067\n",
      "[LOG] Epoch: 07100    | Train ACC: 97.73%    | Loss: 0.067\n",
      "[LOG] Epoch: 07150    | Train ACC: 97.73%    | Loss: 0.067\n",
      "[LOG] Epoch: 07200    | Train ACC: 97.73%    | Loss: 0.067\n",
      "[LOG] Epoch: 07250    | Train ACC: 97.73%    | Loss: 0.067\n",
      "[LOG] Epoch: 07300    | Train ACC: 97.73%    | Loss: 0.067\n",
      "[LOG] Epoch: 07350    | Train ACC: 97.73%    | Loss: 0.067\n",
      "[LOG] Epoch: 07400    | Train ACC: 97.73%    | Loss: 0.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 7433/10000 [00:01<00:00, 3915.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Epoch: 07450    | Train ACC: 97.73%    | Loss: 0.067\n",
      "[LOG] Epoch: 07500    | Train ACC: 97.73%    | Loss: 0.067\n",
      "[LOG] Epoch: 07550    | Train ACC: 97.73%    | Loss: 0.067\n",
      "[LOG] Epoch: 07600    | Train ACC: 97.73%    | Loss: 0.067\n",
      "[LOG] Epoch: 07650    | Train ACC: 97.73%    | Loss: 0.066\n",
      "[LOG] Epoch: 07700    | Train ACC: 97.73%    | Loss: 0.066\n",
      "[LOG] Epoch: 07750    | Train ACC: 97.73%    | Loss: 0.066\n",
      "[LOG] Epoch: 07800    | Train ACC: 97.73%    | Loss: 0.066\n",
      "[LOG] Epoch: 07850    | Train ACC: 97.73%    | Loss: 0.066\n",
      "[LOG] Epoch: 07900    | Train ACC: 97.73%    | Loss: 0.066\n",
      "[LOG] Epoch: 07950    | Train ACC: 97.73%    | Loss: 0.066\n",
      "[LOG] Epoch: 08000    | Train ACC: 97.73%    | Loss: 0.066\n",
      "[LOG] Epoch: 08050    | Train ACC: 97.73%    | Loss: 0.066\n",
      "[LOG] Epoch: 08100    | Train ACC: 97.73%    | Loss: 0.066\n",
      "[LOG] Epoch: 08150    | Train ACC: 97.73%    | Loss: 0.066\n",
      "[LOG] Epoch: 08200    | Train ACC: 97.73%    | Loss: 0.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 8227/10000 [00:02<00:00, 3925.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Epoch: 08250    | Train ACC: 97.73%    | Loss: 0.066\n",
      "[LOG] Epoch: 08300    | Train ACC: 97.73%    | Loss: 0.066\n",
      "[LOG] Epoch: 08350    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 08400    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 08450    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 08500    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 08550    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 08600    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 08650    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 08700    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 08750    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 08800    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 08850    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 08900    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 08950    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 09000    | Train ACC: 97.73%    | Loss: 0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9021/10000 [00:02<00:00, 3938.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Epoch: 09050    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 09100    | Train ACC: 97.73%    | Loss: 0.065\n",
      "[LOG] Epoch: 09150    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09200    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09250    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09300    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09350    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09400    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09450    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09500    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09550    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09600    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09650    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09700    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09750    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09800    | Train ACC: 97.73%    | Loss: 0.064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 3889.33it/s][A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Epoch: 09850    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09900    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 09950    | Train ACC: 97.73%    | Loss: 0.064\n",
      "[LOG] Epoch: 10000    | Train ACC: 97.73%    | Loss: 0.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training process\n",
    "final_model, recorded = Training(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f73c9",
   "metadata": {},
   "source": [
    "Model parameters after training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d91ac62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:\n",
      "  | Weights: Parameter containing:\n",
      "tensor([[ 0.1775,  0.1013,  0.5244,  0.6854,  0.5064,  0.5476,  0.3611, -0.1185,\n",
      "          0.6142,  0.7197,  0.0765, -0.4699,  0.9149, -0.1489,  0.6492,  0.6991,\n",
      "          0.0543, -0.5385, -0.0402,  0.2178, -0.3666, -0.5387,  0.8704,  1.0320,\n",
      "          0.7821,  0.8198,  0.6643,  0.1499,  0.6524,  0.8641,  0.6705]],\n",
      "       requires_grad=True)\n",
      "  | Bias: Parameter containing:\n",
      "tensor([-0.2263], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('Model parameters:')\n",
    "print('  | Weights: %s' % final_model.linear.weight)\n",
    "print('  | Bias: %s'    % final_model.linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b934d",
   "metadata": {},
   "source": [
    "### Virtualize record of training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f6c2519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_graphs(diagnosis_title, record):\n",
    "    accuracies, losses = record\n",
    "    plt.plot(losses)\n",
    "    plt.title(f\"{diagnosis_title} - Training Loss\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Loss\")\n",
    "    plt.show()\n",
    "    plt.plot(accuracies)\n",
    "    plt.title(f\"{diagnosis_title} - Training Accuracy\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Accuracy (Percent %)\")\n",
    "    plt.show()\n",
    "\n",
    "diagnosis_title = 'Breast cancer'\n",
    "plot_graphs(diagnosis_title, recorded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf25b7",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f90ff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Testing Accuracy = 99.12%\n"
     ]
    }
   ],
   "source": [
    "test_acc = compute_accuracy(final_model, X_test, Y_test)\n",
    "print('[+] Testing Accuracy = {}'.format(to_percent(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09624fec",
   "metadata": {},
   "source": [
    "We actually train the machine learning model to diagnose the Breast cancer. As you can see in the graphs, the training loss drops quickly to almost zero and the training accuracy reaches the 98%. The testing accuracy is also 94.74. Notice that this machine learning system diagnoses this disease in a perfect way; whereas human doctors can commit mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49831ce4",
   "metadata": {},
   "source": [
    "## Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7492c434",
   "metadata": {},
   "source": [
    "So far, we have used machine learning in an insecure way. Now, we introduce our proposed encrypted learning model. This is a combination of federated learning and homomorphic encryption!\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='images/encrypted_learning.png'>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c78dc",
   "metadata": {},
   "source": [
    "**Set up**\n",
    "\n",
    "- 1. Define HE scheme, Hospitals shared a HE private key, and share with the Aggregator a public key.\n",
    "- 2. Define the model that use to train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a88fe",
   "metadata": {},
   "source": [
    "**Local training**\n",
    "- 3. Hospitals train locally with the model in plaintext, extract model updates (the final weights) and encrypt them using the private HE key.\n",
    "- 4. Each hospital sends its encrypted model's weights to the Aggregator (untrusted)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e462933f",
   "metadata": {},
   "source": [
    "**Global model weight aggregator**\n",
    "- 5. Aggregator uses its public key to perform homomorphic operation on the encrypted weights to obtain new encrypted model, and send its to hospitals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8648dec4",
   "metadata": {},
   "source": [
    "**Repeated**\n",
    "- 6. Each hospital receives the decrypted model, then uses their private HE key, decrypts its to get the new model.\n",
    "- 7. This process ís repeated until hospitals find the new desired model or after a termination criteria is met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e13ec8",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30edbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa8cfc",
   "metadata": {},
   "source": [
    "### Dataset 1\n",
    "\n",
    "[source](https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset)\n",
    "\n",
    "**Description:**\n",
    "Breast cancer is the most common cancer amongst women in the world. It accounts for 25% of all cancer cases, and affected over 2.1 Million people in 2015 alone. It starts when cells in the breast begin to grow out of control. These cells usually form tumors that can be seen via X-ray or felt as lumps in the breast area.\n",
    "\n",
    "The key challenges against it’s detection is how to classify tumors into malignant (cancerous) or benign(non cancerous). We ask you to complete the analysis of classifying these tumors using machine learning (with SVMs) and the Breast Cancer Wisconsin (Diagnostic) Dataset.\n",
    "\n",
    "**Acknowledgements:**\n",
    "This dataset has been referred from Kaggle.\n",
    "\n",
    "**Objective:**\n",
    "* Understand the Dataset & cleanup (if required).\n",
    "* Build classification models to predict whether the cancer type is Malignant or Benign.\n",
    "* Also fine-tune the hyperparameters & compare the evaluation metrics of various classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4647fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1202, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_pts_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_pts_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dim_worst</th>\n",
       "      <th>diagnostic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>561</td>\n",
       "      <td>20.47</td>\n",
       "      <td>20.67</td>\n",
       "      <td>134.70</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.09156</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.15230</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>...</td>\n",
       "      <td>27.15</td>\n",
       "      <td>152.00</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>0.25340</td>\n",
       "      <td>0.30920</td>\n",
       "      <td>0.16130</td>\n",
       "      <td>0.3220</td>\n",
       "      <td>0.06386</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>11.75</td>\n",
       "      <td>20.18</td>\n",
       "      <td>76.10</td>\n",
       "      <td>419.8</td>\n",
       "      <td>0.10890</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.06843</td>\n",
       "      <td>0.03738</td>\n",
       "      <td>0.1993</td>\n",
       "      <td>...</td>\n",
       "      <td>26.21</td>\n",
       "      <td>88.91</td>\n",
       "      <td>543.9</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.18920</td>\n",
       "      <td>0.19560</td>\n",
       "      <td>0.07909</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.07987</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>13.77</td>\n",
       "      <td>13.27</td>\n",
       "      <td>88.06</td>\n",
       "      <td>582.7</td>\n",
       "      <td>0.09198</td>\n",
       "      <td>0.06221</td>\n",
       "      <td>0.01063</td>\n",
       "      <td>0.01917</td>\n",
       "      <td>0.1592</td>\n",
       "      <td>...</td>\n",
       "      <td>16.93</td>\n",
       "      <td>94.17</td>\n",
       "      <td>661.1</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.03732</td>\n",
       "      <td>0.05802</td>\n",
       "      <td>0.2823</td>\n",
       "      <td>0.06794</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>231</td>\n",
       "      <td>12.34</td>\n",
       "      <td>14.95</td>\n",
       "      <td>78.29</td>\n",
       "      <td>469.1</td>\n",
       "      <td>0.08682</td>\n",
       "      <td>0.04571</td>\n",
       "      <td>0.02109</td>\n",
       "      <td>0.02054</td>\n",
       "      <td>0.1571</td>\n",
       "      <td>...</td>\n",
       "      <td>16.85</td>\n",
       "      <td>84.11</td>\n",
       "      <td>533.1</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.06744</td>\n",
       "      <td>0.04921</td>\n",
       "      <td>0.04793</td>\n",
       "      <td>0.2298</td>\n",
       "      <td>0.05974</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410</td>\n",
       "      <td>13.80</td>\n",
       "      <td>15.79</td>\n",
       "      <td>90.43</td>\n",
       "      <td>584.1</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.12800</td>\n",
       "      <td>0.07789</td>\n",
       "      <td>0.05069</td>\n",
       "      <td>0.1662</td>\n",
       "      <td>...</td>\n",
       "      <td>20.86</td>\n",
       "      <td>110.30</td>\n",
       "      <td>812.4</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.35420</td>\n",
       "      <td>0.27790</td>\n",
       "      <td>0.13830</td>\n",
       "      <td>0.2589</td>\n",
       "      <td>0.10300</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0  561        20.47         20.67          134.70     1299.0          0.09156   \n",
       "1   77        11.75         20.18           76.10      419.8          0.10890   \n",
       "2  151        13.77         13.27           88.06      582.7          0.09198   \n",
       "3  231        12.34         14.95           78.29      469.1          0.08682   \n",
       "4  410        13.80         15.79           90.43      584.1          0.10070   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave_pts_mean  symmetry_mean  ...  \\\n",
       "0           0.13130         0.15230           0.10150         0.2166  ...   \n",
       "1           0.11410         0.06843           0.03738         0.1993  ...   \n",
       "2           0.06221         0.01063           0.01917         0.1592  ...   \n",
       "3           0.04571         0.02109           0.02054         0.1571  ...   \n",
       "4           0.12800         0.07789           0.05069         0.1662  ...   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0          27.15           152.00      1645.0            0.1097   \n",
       "1          26.21            88.91       543.9            0.1358   \n",
       "2          16.93            94.17       661.1            0.1170   \n",
       "3          16.85            84.11       533.1            0.1048   \n",
       "4          20.86           110.30       812.4            0.1411   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave_pts_worst  symmetry_worst  \\\n",
       "0            0.25340          0.30920            0.16130          0.3220   \n",
       "1            0.18920          0.19560            0.07909          0.3168   \n",
       "2            0.10720          0.03732            0.05802          0.2823   \n",
       "3            0.06744          0.04921            0.04793          0.2298   \n",
       "4            0.35420          0.27790            0.13830          0.2589   \n",
       "\n",
       "   fractal_dim_worst  diagnostic  \n",
       "0            0.06386           M  \n",
       "1            0.07987           B  \n",
       "2            0.06794           B  \n",
       "3            0.05974           B  \n",
       "4            0.10300           M  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('data/dataset1.csv')\n",
    "print(\"Shape:\", df1.shape)\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32f3373",
   "metadata": {},
   "source": [
    "### Dataset 2\n",
    "\n",
    "[source](https://www.kaggle.com/code/a3amat02/breast-cancer-classification/input)\n",
    "\n",
    "**About this file**\n",
    "\n",
    "* y. The outcomes. A factor with two levels denoting whether a mass is malignant (\"M\") or benign (\"B\").\n",
    "* x. The predictors. A matrix with the mean, standard error and worst value of each of 10 nuclear measurements on the slide, for 30 total features per biopsy:\n",
    "* radius. Nucleus radius (mean of distances from center to points on perimeter).\n",
    "* texture. Nucleus texture (standard deviation of grayscale values).\n",
    "* perimeter. Nucleus perimeter.\n",
    "* area. Nucleus area.\n",
    "* smoothness. Nucleus smoothness (local variation in radius lengths).\n",
    "* compactness. Nucleus compactness (perimeter^2/area - 1).\n",
    "* concavity, Nucleus concavity (severity of concave portions of the contour).\n",
    "* concave_pts. Number of concave portions of the nucleus contour.\n",
    "* symmetry. Nucleus symmetry.\n",
    "* fractal_dim. Nucleus fractal dimension (\"coastline approximation\" -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "324d6157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1193, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_pts_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_pts_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dim_worst</th>\n",
       "      <th>diagnostic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>374</td>\n",
       "      <td>14.68</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>...</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.14640</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325</td>\n",
       "      <td>12.34</td>\n",
       "      <td>12.27</td>\n",
       "      <td>78.94</td>\n",
       "      <td>468.5</td>\n",
       "      <td>0.09003</td>\n",
       "      <td>0.06307</td>\n",
       "      <td>0.029580</td>\n",
       "      <td>0.026470</td>\n",
       "      <td>0.1689</td>\n",
       "      <td>...</td>\n",
       "      <td>19.27</td>\n",
       "      <td>87.22</td>\n",
       "      <td>564.9</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.20740</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.10700</td>\n",
       "      <td>0.3110</td>\n",
       "      <td>0.07592</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.070170</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264</td>\n",
       "      <td>14.80</td>\n",
       "      <td>17.66</td>\n",
       "      <td>95.88</td>\n",
       "      <td>674.8</td>\n",
       "      <td>0.09179</td>\n",
       "      <td>0.08890</td>\n",
       "      <td>0.040690</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.1893</td>\n",
       "      <td>...</td>\n",
       "      <td>22.74</td>\n",
       "      <td>105.90</td>\n",
       "      <td>829.5</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.18810</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.08308</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.07285</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161</td>\n",
       "      <td>13.50</td>\n",
       "      <td>12.71</td>\n",
       "      <td>85.69</td>\n",
       "      <td>566.2</td>\n",
       "      <td>0.07376</td>\n",
       "      <td>0.03614</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>...</td>\n",
       "      <td>16.94</td>\n",
       "      <td>95.48</td>\n",
       "      <td>698.7</td>\n",
       "      <td>0.09023</td>\n",
       "      <td>0.05836</td>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.02210</td>\n",
       "      <td>0.2267</td>\n",
       "      <td>0.06192</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0  374        14.68         20.13           94.74      684.5          0.09867   \n",
       "1  325        12.34         12.27           78.94      468.5          0.09003   \n",
       "2  359        20.57         17.77          132.90     1326.0          0.08474   \n",
       "3  264        14.80         17.66           95.88      674.8          0.09179   \n",
       "4  161        13.50         12.71           85.69      566.2          0.07376   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave_pts_mean  symmetry_mean  ...  \\\n",
       "0           0.07200        0.073950          0.052590         0.1586  ...   \n",
       "1           0.06307        0.029580          0.026470         0.1689  ...   \n",
       "2           0.07864        0.086900          0.070170         0.1812  ...   \n",
       "3           0.08890        0.040690          0.022600         0.1893  ...   \n",
       "4           0.03614        0.002758          0.004419         0.1365  ...   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0          30.88           123.40      1138.0           0.14640   \n",
       "1          19.27            87.22       564.9           0.12920   \n",
       "2          23.41           158.80      1956.0           0.12380   \n",
       "3          22.74           105.90       829.5           0.12260   \n",
       "4          16.94            95.48       698.7           0.09023   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave_pts_worst  symmetry_worst  \\\n",
       "0            0.18710          0.29140            0.16090          0.3029   \n",
       "1            0.20740          0.17910            0.10700          0.3110   \n",
       "2            0.18660          0.24160            0.18600          0.2750   \n",
       "3            0.18810          0.20600            0.08308          0.3600   \n",
       "4            0.05836          0.01379            0.02210          0.2267   \n",
       "\n",
       "   fractal_dim_worst  diagnostic  \n",
       "0            0.08216           M  \n",
       "1            0.07592           B  \n",
       "2            0.08902           M  \n",
       "3            0.07285           B  \n",
       "4            0.06192           B  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('data/dataset2.csv')\n",
    "print(\"Shape:\", df2.shape)\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebe8356",
   "metadata": {},
   "source": [
    "### Dataset 3\n",
    "\n",
    "[source](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))\n",
    "\n",
    "**Data Set Information:**\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. A few of the images can be found at [Web Link]\n",
    "\n",
    "Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\n",
    "\n",
    "The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "This database is also available through the UW CS ftp server:\n",
    "ftp ftp.cs.wisc.edu\n",
    "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "\n",
    "**Attribute Information:**\n",
    "\n",
    "1) ID number\n",
    "\n",
    "2) Diagnosis (M = malignant, B = benign)\n",
    "\n",
    "3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter)\n",
    "\n",
    "b) texture (standard deviation of gray-scale values)\n",
    "\n",
    "c) perimeter\n",
    "\n",
    "d) area\n",
    "\n",
    "e) smoothness (local variation in radius lengths)\n",
    "\n",
    "f) compactness (perimeter^2 / area - 1.0)\n",
    "\n",
    "g) concavity (severity of concave portions of the contour)\n",
    "\n",
    "h) concave points (number of concave portions of the contour)\n",
    "\n",
    "i) symmetry\n",
    "\n",
    "j) fractal dimension (\"coastline approximation\" - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "acb6ee1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1189, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_pts_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_pts_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dim_worst</th>\n",
       "      <th>diagnostic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>529</td>\n",
       "      <td>15.49</td>\n",
       "      <td>19.97</td>\n",
       "      <td>102.40</td>\n",
       "      <td>744.7</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>0.15620</td>\n",
       "      <td>0.18910</td>\n",
       "      <td>0.09113</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.41</td>\n",
       "      <td>142.10</td>\n",
       "      <td>1359.0</td>\n",
       "      <td>0.1681</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>0.55530</td>\n",
       "      <td>0.21210</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.10190</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.26780</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>447</td>\n",
       "      <td>13.43</td>\n",
       "      <td>19.63</td>\n",
       "      <td>85.84</td>\n",
       "      <td>565.4</td>\n",
       "      <td>0.09048</td>\n",
       "      <td>0.06288</td>\n",
       "      <td>0.05858</td>\n",
       "      <td>0.03438</td>\n",
       "      <td>0.1598</td>\n",
       "      <td>...</td>\n",
       "      <td>29.87</td>\n",
       "      <td>116.60</td>\n",
       "      <td>993.6</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>0.26440</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.07371</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>12.77</td>\n",
       "      <td>29.43</td>\n",
       "      <td>81.35</td>\n",
       "      <td>507.9</td>\n",
       "      <td>0.08276</td>\n",
       "      <td>0.04234</td>\n",
       "      <td>0.01997</td>\n",
       "      <td>0.01499</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>...</td>\n",
       "      <td>36.00</td>\n",
       "      <td>88.10</td>\n",
       "      <td>594.7</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.08653</td>\n",
       "      <td>0.06498</td>\n",
       "      <td>0.2407</td>\n",
       "      <td>0.06484</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>12.00</td>\n",
       "      <td>15.65</td>\n",
       "      <td>76.95</td>\n",
       "      <td>443.3</td>\n",
       "      <td>0.09723</td>\n",
       "      <td>0.07165</td>\n",
       "      <td>0.04151</td>\n",
       "      <td>0.01863</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>...</td>\n",
       "      <td>24.90</td>\n",
       "      <td>87.78</td>\n",
       "      <td>567.9</td>\n",
       "      <td>0.1377</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>0.22670</td>\n",
       "      <td>0.07632</td>\n",
       "      <td>0.3379</td>\n",
       "      <td>0.07924</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0  529        15.49         19.97          102.40      744.7          0.11600   \n",
       "1  365        13.71         20.83           90.20      577.9          0.11890   \n",
       "2  447        13.43         19.63           85.84      565.4          0.09048   \n",
       "3  347        12.77         29.43           81.35      507.9          0.08276   \n",
       "4   27        12.00         15.65           76.95      443.3          0.09723   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave_pts_mean  symmetry_mean  ...  \\\n",
       "0           0.15620         0.18910           0.09113         0.1929  ...   \n",
       "1           0.16450         0.09366           0.05985         0.2196  ...   \n",
       "2           0.06288         0.05858           0.03438         0.1598  ...   \n",
       "3           0.04234         0.01997           0.01499         0.1539  ...   \n",
       "4           0.07165         0.04151           0.01863         0.2079  ...   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0          29.41           142.10      1359.0            0.1681   \n",
       "1          28.14           110.60       897.0            0.1654   \n",
       "2          29.87           116.60       993.6            0.1401   \n",
       "3          36.00            88.10       594.7            0.1234   \n",
       "4          24.90            87.78       567.9            0.1377   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave_pts_worst  symmetry_worst  \\\n",
       "0             0.3913          0.55530            0.21210          0.3187   \n",
       "1             0.3682          0.26780            0.15560          0.3196   \n",
       "2             0.1546          0.26440            0.11600          0.2884   \n",
       "3             0.1064          0.08653            0.06498          0.2407   \n",
       "4             0.2003          0.22670            0.07632          0.3379   \n",
       "\n",
       "   fractal_dim_worst  diagnostic  \n",
       "0            0.10190           M  \n",
       "1            0.11510           M  \n",
       "2            0.07371           M  \n",
       "3            0.06484           B  \n",
       "4            0.07924           B  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv('data/dataset3.csv')\n",
    "print(\"Shape:\", df3.shape)\n",
    "df3.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc06478",
   "metadata": {},
   "source": [
    "In this demo, there are 3 hospitals (with corresponding datasets above) but there could be more hospitals. The 3 hospitals cannot share the cases of their patients because they are competitors and it is necessary to protect the privacy of patients. Hence, the ML model will be learned in a federated way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eceeb3f",
   "metadata": {},
   "source": [
    "## Clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b814944",
   "metadata": {},
   "source": [
    "Import openFHE library. Then run `generate_key()`, this is just a python wrapper to run `openfhe-lib/build/key_gen`. After running this files, it will create `openfhe-lib/data` folder that holds:\n",
    "- `crypto_context.txt` : contain CKKS CryptoContext object\n",
    "- `public_key.txt`     : contain CKKS public key\n",
    "- `private_key.txt`    : contain CKKS private key\n",
    "- `mult_key.txt`       : contain CKKS multiplication key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c90acd04",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 193] %1 is not a valid Win32 application",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenfhe_lib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mckks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mopenFHE\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m \n\u001b[0;32m      3\u001b[0m \u001b[39m# === Generate Key-pairs of CKKS Context ===\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m generate_keys()\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\OneDrive\\Bureau\\ahlemfederated\\homorphicencryption\\fedratedd\\fedlearning\\openfhe_lib\\ckks\\openFHE.py:15\u001b[0m, in \u001b[0;36mgenerate_keys\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_keys\u001b[39m():\n\u001b[0;32m      8\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Just a python wrapper to run ./build/key_gen. After running this files, it will\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m        create `./data` folders that holds:\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m        - `crypto_context.txt` : contain CKKS CryptoContext object\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m        - `mult_key.txt`       : contain CKKS multiplication key\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     subprocess\u001b[39m.\u001b[39;49mrun(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mcwd\u001b[39m}\u001b[39;49;00m\u001b[39m/build/key_generation\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    550\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m, timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1024\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1020\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m   1021\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m   1022\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m-> 1024\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1025\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1026\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1027\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1028\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1029\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1030\u001b[0m                         restore_signals,\n\u001b[0;32m   1031\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1032\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1033\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m   1034\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1493\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1491\u001b[0m \u001b[39m# Start the process\u001b[39;00m\n\u001b[0;32m   1492\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1493\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1494\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1495\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1496\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1497\u001b[0m                              creationflags,\n\u001b[0;32m   1498\u001b[0m                              env,\n\u001b[0;32m   1499\u001b[0m                              cwd,\n\u001b[0;32m   1500\u001b[0m                              startupinfo)\n\u001b[0;32m   1501\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1502\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1506\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1509\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1510\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 193] %1 is not a valid Win32 application"
     ]
    }
   ],
   "source": [
    "from openfhe_lib.ckks.openFHE import * \n",
    "\n",
    "# === Generate Key-pairs of CKKS Context ===\n",
    "generate_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efbea12",
   "metadata": {},
   "source": [
    "First, we start by creating the `Client` class that simulate the computers of each hospital. This just rewrite the Logistic Regression process that we have implemented previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00ea04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, name, data_url, enc_file, n_features, iters):\n",
    "        self.id = name\n",
    "        self.enc_file = enc_file  # place wher clients save encrypted weights\n",
    "        \n",
    "        # split data into train and test\n",
    "        self.X_train, self.Y_train, self.X_test, self.Y_test = self.preprocessing(data_url)\n",
    "        \n",
    "        # define local training model\n",
    "        self.local_model = LogisticRegression(n_features)\n",
    "        \n",
    "        # some helpfull stuffs\n",
    "        self.decide_vectorized = np.vectorize(self.decide)\n",
    "        self.to_percent = lambda x: '{:.2f}%'.format(x)\n",
    "        self.num_epochs = iters\n",
    "        self.accuracies = []\n",
    "        self.losses = []\n",
    "        \n",
    "    def preprocessing(self, data_url):\n",
    "        df = pd.read_csv(data_url)\n",
    "        # Replace \"M\" with 1 and \"B\" with 0 at \"diagnostic\" column\n",
    "        df[\"diagnostic\"] = (df[\"diagnostic\"] == \"M\").astype(int)\n",
    "        \n",
    "        # split dataframe to train and test df\n",
    "        df_train, df_test = np.split(df.sample(frac=1), [int(0.8 * len(df))])\n",
    "        \n",
    "        # scaling and convert to tensor context\n",
    "        train, X_train, Y_train = scale_dataset(df_train, True)\n",
    "        test , X_test , Y_test  = scale_dataset(df_test , False)\n",
    "        return X_train, Y_train, X_test, Y_test\n",
    "    \n",
    "    def decide(self, y):\n",
    "        return 1. if y >= 0.5 else 0.\n",
    "    \n",
    "    def compute_accuracy(self, input, output):\n",
    "        prediction = self.local_model(input).data.numpy()[:, 0]\n",
    "        n_samples = prediction.shape[0] + 0.\n",
    "        prediction = self.decide_vectorized(prediction)\n",
    "        equal = prediction == output.data.numpy()\n",
    "        return 100. * equal.sum() / n_samples\n",
    "    \n",
    "    def local_training(self, debug=True):\n",
    "        n_samples, _ = self.X_train.shape\n",
    "\n",
    "        # define criterion function and set up optimizer\n",
    "        criterion = torch.nn.BCELoss(reduction='mean')\n",
    "        optimizer = torch.optim.SGD(self.local_model.parameters(), lr=0.01)  \n",
    "\n",
    "        # main process\n",
    "        for epoch in range(self.num_epochs):  \n",
    "            optimizer.zero_grad()\n",
    "            #### Compute outputs ####\n",
    "            prediction = self.local_model(self.X_train)\n",
    "\n",
    "            #### Compute gradients ####\n",
    "            loss = criterion(prediction.squeeze(), self.Y_train)\n",
    "            loss.backward()\n",
    "\n",
    "            #### Update weights #### \n",
    "            optimizer.step()\n",
    "\n",
    "            # compute accuracy and loss\n",
    "            train_acc = self.compute_accuracy(self.X_train, self.Y_train)\n",
    "            train_loss = loss.item()\n",
    "                \n",
    "            self.losses.append(train_loss)\n",
    "            self.accuracies.append(train_acc)\n",
    "        \n",
    "            #### Logging ####\n",
    "            if debug and (epoch + 1)%50 == 0:\n",
    "                print('[LOG] Epoch: %05d' % (epoch + 1), end=\"\")\n",
    "                print('    | Train ACC: %s' % self.to_percent(train_acc), end=\"\")\n",
    "                print('    | Loss: %.3f' % train_loss)\n",
    "    \n",
    "    def encrypted_model_params(self):\n",
    "        model_weights = self.local_model.linear.weight.data.squeeze().tolist()\n",
    "        model_bias    = self.local_model.linear.bias.data.squeeze().tolist()\n",
    "        \n",
    "        model_params  = model_weights + [model_bias]\n",
    "        encrypt_weights(model_params, self.enc_file)\n",
    "        \n",
    "    def decrypted_model_params(self):\n",
    "        params = decrypt_weights(\"/enc_aggregator_weight_server.txt\")\n",
    "        # convert float to tensor context\n",
    "        W = Variable(torch.tensor([params[:-1]], dtype = torch.float32))\n",
    "        B = Variable(torch.tensor( params[-1], dtype = torch.float32))\n",
    "        \n",
    "        self.local_model.linear.weight = nn.Parameter(W)\n",
    "        self.local_model.linear.bias   = nn.Parameter(B)\n",
    "    \n",
    "    def plot_graphs(self, diagnosis_title = 'Breast cancer'):\n",
    "        plt.plot(self.losses)\n",
    "        plt.title(f\"{diagnosis_title} - Training Loss\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Training Loss\")\n",
    "        plt.show()\n",
    "        plt.plot(self.accuracies)\n",
    "        plt.title(f\"{diagnosis_title} - Training Accuracy\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Training Accuracy (Percent %)\")\n",
    "        plt.show()\n",
    "    \n",
    "    def print_result_after_training(self):\n",
    "        print('Model parameters:')\n",
    "        print('  | Weights: %s' % self.local_model.linear.weight)\n",
    "        print('  | Bias: %s' % self.local_model.linear.bias)\n",
    "        self.plot_graphs()\n",
    "    \n",
    "    def evaluating_model(self):\n",
    "        test_acc = self.compute_accuracy(self.X_test, self.Y_test)\n",
    "        print('[+] Testing Accuracy = {}'.format(self.to_percent(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d0e24f",
   "metadata": {},
   "source": [
    "## Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586569f",
   "metadata": {},
   "source": [
    "We define some functions to train the machine learning model in a federated way while keeping track of the training loss and the training accuracy, for each hospital separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9eaeed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [\n",
    "    Client('Hostpital1', 'data/dataset1.csv', \"/enc_weight_client1.txt\", n_features=31, iters=10), \n",
    "    Client('Hostpital2', 'data/dataset2.csv', \"/enc_weight_client2.txt\", n_features=31, iters=10),\n",
    "    Client('Hostpital3', 'data/dataset3.csv', \"/enc_weight_client3.txt\", n_features=31, iters=10),\n",
    "    Client('Hostpital4', 'data/dataset4.csv', \"/enc_weight_client4.txt\", n_features=31, iters=10)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa622e2b",
   "metadata": {},
   "source": [
    "The whole process is done in a server aggregator, in 1000 iterations (we can vary the number of iterations.) At each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25d8335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1000 #2000\n",
    "worker_iterations = 5\n",
    "to_percent = lambda x: '{:.2f}%'.format(x)\n",
    "n_hospitals = len(clients)\n",
    "n_features = 31\n",
    "    \n",
    "def compute_federated_accuracy(model, input, output):\n",
    "    prediction = model(input)\n",
    "    n_samples = prediction.shape[0]\n",
    "    s = 0.\n",
    "    for i in range(n_samples):\n",
    "        p = 1. if prediction[i] >= 0.5 else 0.\n",
    "        e = 1. if p == output[i] else 0.\n",
    "        s += e\n",
    "    return 100. * s / n_samples\n",
    "\n",
    "def federated_learning(clients):\n",
    "    # init global training model\n",
    "    global_model = LogisticRegression(n_features)\n",
    "\n",
    "    # record losses and accuracies report from clients\n",
    "    losses = [[] for i in range(n_hospitals)]\n",
    "    accuracies = [[] for i in range(n_hospitals)]\n",
    "    \n",
    "    pbar = tqdm(range(iterations), desc='Federated Learning Process')\n",
    "    for iteration in pbar:\n",
    "        if iteration:\n",
    "            # copy global model to clients\n",
    "            # clients will receive the weight-aggregated from server, extract\n",
    "            # the ciphertext then decrypt it to get to global_model's weights\n",
    "            for i in range(n_hospitals):\n",
    "                clients[i].decrypted_model_params()\n",
    "        \n",
    "        # perform local training for each clients then report acc and loss to server\n",
    "        for i in range(n_hospitals):\n",
    "            clients[i].local_training(debug=False)\n",
    "            \n",
    "            # report to server\n",
    "            losses[i].append(clients[i].losses[-1])\n",
    "            accuracies[i].append(clients[i].accuracies[-1])\n",
    "        \n",
    "        # clients encrypt the final weights of local model after training\n",
    "        for i in range(n_hospitals):\n",
    "            clients[i].encrypted_model_params()\n",
    "        \n",
    "        # server collect clients's encrypted weights then perform weight-aggregation\n",
    "        # by using homomorphic operation\n",
    "        with torch.no_grad():\n",
    "            # avg_weight = sum([clients[i].local_model.linear.weight.data for i in range(n_hospitals)]) / n_hospitals\n",
    "            # global_model.linear.weight = nn.Parameter(avg_weight)\n",
    "            # avg_bias = sum([clients[i].local_model.linear.bias.data for i in range(n_hospitals)]) / n_hospitals\n",
    "            # global_model.linear.bias = nn.Parameter(avg_bias)\n",
    "            aggregator()\n",
    "    \n",
    "        # logging\n",
    "        if (iteration + 1) % 100 == 0:\n",
    "            losses_str = ['{:.4f}'.format(losses[i][-1]) for i in range(n_hospitals)]\n",
    "            accuracies_str = [to_percent(accuracies[i][-1]) for i in range(n_hospitals)]\n",
    "            print('[LOG] Epoch = {0:04d}\\n> Losses = {1}\\n> Accuracies = {2}'.format(iteration + 1, losses_str, accuracies_str))\n",
    "        \n",
    "    return losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4cb88a05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Federated Learning Process:   0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 193] %1 is not a valid Win32 application",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m losses, accuracies \u001b[39m=\u001b[39m federated_learning(clients)\n",
      "Cell \u001b[1;32mIn[46], line 44\u001b[0m, in \u001b[0;36mfederated_learning\u001b[1;34m(clients)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39m# clients encrypt the final weights of local model after training\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_hospitals):\n\u001b[1;32m---> 44\u001b[0m     clients[i]\u001b[39m.\u001b[39;49mencrypted_model_params()\n\u001b[0;32m     46\u001b[0m \u001b[39m# server collect clients's encrypted weights then perform weight-aggregation\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39m# by using homomorphic operation\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     49\u001b[0m     \u001b[39m# avg_weight = sum([clients[i].local_model.linear.weight.data for i in range(n_hospitals)]) / n_hospitals\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[39m# global_model.linear.weight = nn.Parameter(avg_weight)\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     \u001b[39m# avg_bias = sum([clients[i].local_model.linear.bias.data for i in range(n_hospitals)]) / n_hospitals\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[39m# global_model.linear.bias = nn.Parameter(avg_bias)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[44], line 80\u001b[0m, in \u001b[0;36mClient.encrypted_model_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     77\u001b[0m model_bias    \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_model\u001b[39m.\u001b[39mlinear\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     79\u001b[0m model_params  \u001b[39m=\u001b[39m model_weights \u001b[39m+\u001b[39m [model_bias]\n\u001b[1;32m---> 80\u001b[0m encrypt_weights(model_params, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menc_file)\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\OneDrive\\Bureau\\ahlemfederated\\homorphicencryption\\fedratedd\\fedlearning\\openfhe_lib\\ckks\\openFHE.py:22\u001b[0m, in \u001b[0;36mencrypt_weights\u001b[1;34m(weights, output_filename)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencrypt_weights\u001b[39m(weights, output_filename):\n\u001b[0;32m     18\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" This function will be used by clients to encrypt local model's weights and send its to server.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m        - weights         : vector of model's weights (float numbers)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m        - output_filename : store the output of encrypted_weights (as `Ciphertext<DCRTPoly>` object) to `output_filename`.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     subprocess\u001b[39m.\u001b[39;49mrun([\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mcwd\u001b[39m}\u001b[39;49;00m\u001b[39m/build/client\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_filename, \u001b[39m\"\u001b[39;49m\u001b[39m@\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin([\u001b[39mstr\u001b[39;49m(w) \u001b[39mfor\u001b[39;49;00m w \u001b[39min\u001b[39;49;00m weights])])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    550\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m, timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1024\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1020\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m   1021\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m   1022\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m-> 1024\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1025\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1026\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1027\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1028\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1029\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1030\u001b[0m                         restore_signals,\n\u001b[0;32m   1031\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1032\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1033\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m   1034\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1493\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1491\u001b[0m \u001b[39m# Start the process\u001b[39;00m\n\u001b[0;32m   1492\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1493\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1494\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1495\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1496\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1497\u001b[0m                              creationflags,\n\u001b[0;32m   1498\u001b[0m                              env,\n\u001b[0;32m   1499\u001b[0m                              cwd,\n\u001b[0;32m   1500\u001b[0m                              startupinfo)\n\u001b[0;32m   1501\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1502\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1506\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1509\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1510\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 193] %1 is not a valid Win32 application"
     ]
    }
   ],
   "source": [
    "losses, accuracies = federated_learning(clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774719fe",
   "metadata": {},
   "source": [
    "### Virtualize record of training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b594544e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     plt\u001b[39m.\u001b[39mylabel(\u001b[39m\"\u001b[39m\u001b[39mTraining Accuracy (Percent \u001b[39m\u001b[39m%\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> 17\u001b[0m plot_federated_graphs(\u001b[39m'\u001b[39m\u001b[39mBreast cancer\u001b[39m\u001b[39m'\u001b[39m, losses, accuracies)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_federated_graphs(diagnosis_title, losses, accuracies):\n",
    "    for i in range(n_hospitals):\n",
    "        plt.plot(losses[i], label=f'Hospital {i+1}')\n",
    "    legend = plt.legend(loc='upper right', shadow=True)\n",
    "    plt.title(f\"{diagnosis_title} - Training Loss\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Loss\")\n",
    "    plt.show()\n",
    "    for i in range(n_hospitals):\n",
    "        plt.plot(accuracies[i], label=f'Hospital {i+1}')\n",
    "    legend = plt.legend(loc='lower right', shadow=True)\n",
    "    plt.title(f\"{diagnosis_title} - Training Accuracy\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Accuracy (Percent %)\")\n",
    "    plt.show()\n",
    "\n",
    "plot_federated_graphs('Breast cancer', losses, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407c111",
   "metadata": {},
   "source": [
    "### Model parameters after training proccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "59337487",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 193] %1 is not a valid Win32 application",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clients[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mdecrypted_model_params()\n\u001b[0;32m      2\u001b[0m global_model \u001b[39m=\u001b[39m clients[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mlocal_model\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mModel parameters:\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[44], line 83\u001b[0m, in \u001b[0;36mClient.decrypted_model_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecrypted_model_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 83\u001b[0m     params \u001b[39m=\u001b[39m decrypt_weights(\u001b[39m\"\u001b[39;49m\u001b[39m/enc_aggregator_weight_server.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     84\u001b[0m     \u001b[39m# convert float to tensor context\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     W \u001b[39m=\u001b[39m Variable(torch\u001b[39m.\u001b[39mtensor([params[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]], dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfloat32))\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\OneDrive\\Bureau\\ahlemfederated\\homorphicencryption\\fedratedd\\fedlearning\\openfhe_lib\\ckks\\openFHE.py:29\u001b[0m, in \u001b[0;36mdecrypt_weights\u001b[1;34m(cipher_file)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecrypt_weights\u001b[39m(cipher_file) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mfloat\u001b[39m]:\n\u001b[0;32m     25\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" This function will be used by clients to decrypt aggregated global model's weights.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39m        - cipher_file     : contain aggregated_weights compute using homomorphic operations by server\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     stdout \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mrun([\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mcwd\u001b[39m}\u001b[39;49;00m\u001b[39m/build/client\u001b[39;49m\u001b[39m\"\u001b[39;49m, cipher_file], capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mdecode()\n\u001b[0;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mfloat\u001b[39m(w) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m stdout\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m@\u001b[39m\u001b[39m\"\u001b[39m)]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    550\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m, timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1024\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1020\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m   1021\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m   1022\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m-> 1024\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1025\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1026\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1027\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1028\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1029\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1030\u001b[0m                         restore_signals,\n\u001b[0;32m   1031\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1032\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1033\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m   1034\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1493\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1491\u001b[0m \u001b[39m# Start the process\u001b[39;00m\n\u001b[0;32m   1492\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1493\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1494\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1495\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1496\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1497\u001b[0m                              creationflags,\n\u001b[0;32m   1498\u001b[0m                              env,\n\u001b[0;32m   1499\u001b[0m                              cwd,\n\u001b[0;32m   1500\u001b[0m                              startupinfo)\n\u001b[0;32m   1501\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1502\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1506\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1509\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1510\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 193] %1 is not a valid Win32 application"
     ]
    }
   ],
   "source": [
    "clients[0].decrypted_model_params()\n",
    "global_model = clients[0].local_model\n",
    "\n",
    "print('\\nModel parameters:')\n",
    "print('  | Weights: %s' % global_model.linear.weight) ### Virtualize record of training processlobal_model.linear.weight)\n",
    "print('  | Bias: %s' % global_model.linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85d5ece",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4520ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Accuracy = 85.71%\n"
     ]
    }
   ],
   "source": [
    "# prepare data for testing model\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test[\"diagnostic\"] = (df_test[\"diagnostic\"] == \"M\").astype(int)\n",
    "test , X_test , Y_test  = scale_dataset(df_test , False)\n",
    "\n",
    "test_acc = compute_federated_accuracy(global_model, X_test, Y_test)\n",
    "print('\\nTesting Accuracy = {}'.format(to_percent(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7328053",
   "metadata": {},
   "source": [
    "## Thanks for reading!\n",
    "I hope you have enjoyed the explanations of this machine learning system with federated learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2312754b",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- [1] Wibawa, F., Catak, F. O., Kuzlu, M., Sarp, S., & Cali, U. (2022, June). Homomorphic encryption and federated learning based privacy-preserving cnn training: Covid-19 detection use-case. In Proceedings of the 2022 European Interdisciplinary Cybersecurity Conference (pp. 85-90).​\n",
    "\n",
    "- [2] Al Badawi, A., Bates, J., Bergamaschi, F., Cousins, D. B., Erabelli, S., Genise, N., ... & Zucca, V. (2022, November). OpenFHE: Open-source fully homomorphic encryption library. In Proceedings of the 10th Workshop on Encrypted Computing & Applied Homomorphic Cryptography (pp. 53-63)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
